{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------\n",
    "# <center>- Spark Project - SD 701 - Data Mining-</center>\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***A RETRAVAILLER***\n",
    "\n",
    "After we evaluated the list of recommended movies, we quickly identified two obvious limitations in our KNN approach. One is the “popularity bias”, the other is “item cold-start problem”. There will be another limitation, “scalability issue”, if the underlying training data is too big to fit in one machine.\n",
    "\n",
    "* popularity bias : refers to system recommends the movies with the most interactions without any personalization\n",
    "* item cold-start problem : refers to when movies added to the catalogue have either none or very little interactions while recommender rely on the movie’s interactions to make recommendations\n",
    "* scalability issue : refers to lack of the ability to scale to much larger sets of data when more and more users and movies added into our database\n",
    "\n",
    "All three above are very typical challenges for collaborative filtering recommender. They arrive naturally along with the user-movie (or movie-user) interaction matrix where each entry records an interaction of a user i and a movie j. In a real world setting, the vast majority of movies receive very few or even no ratings at all by users. We are looking at an extremely sparse matrix with many entries that are missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "#from pyspark import SparkConf, SparkContext\n",
    "\n",
    "#from pyspark.ml.classification import LogisticRegression\n",
    "#from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "from pyspark.sql import Row, SparkSession\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialisation de la session spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Recommendation_system').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Chargement et préparation des données d'évaluations des films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "|     1|     70|   3.0|964982400|\n",
      "|     1|    101|   5.0|964980868|\n",
      "|     1|    110|   4.0|964982176|\n",
      "|     1|    151|   5.0|964984041|\n",
      "|     1|    157|   5.0|964984100|\n",
      "+------+-------+------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_data = \"/home/p5hngk/Downloads/GitHub/SD_701---Data_Mining/ml-latest-small\"\n",
    "\n",
    "df_ratings = spark.read.format(\"csv\").option(\"header\", \"true\").load(path_data+\"/ratings.csv\")\n",
    "df_ratings.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      1|   4.0|\n",
      "|     1|      3|   4.0|\n",
      "|     1|      6|   4.0|\n",
      "|     1|     47|   5.0|\n",
      "|     1|     50|   5.0|\n",
      "|     1|     70|   3.0|\n",
      "|     1|    101|   5.0|\n",
      "|     1|    110|   4.0|\n",
      "|     1|    151|   5.0|\n",
      "|     1|    157|   5.0|\n",
      "+------+-------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings1 = df_ratings.select(df_ratings['userId'], df_ratings['movieId'], df_ratings['rating'])\n",
    "df_ratings1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de réaliser un modèle ALS, il faut que toutes nos données soient au format integer ou float pour pouvoir réaliser les calculs, ce qui n'est pas le cas actuellement. Occupons-nous donc dans un premier temps de changer cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "\n",
    "df_ratings1 = df_ratings1.withColumn(\"userId\", df_ratings1[\"userId\"].cast(IntegerType())) \\\n",
    "                .withColumn(\"movieId\", df_ratings1[\"movieId\"].cast(IntegerType())) \\\n",
    "                .withColumn(\"rating\", df_ratings1[\"rating\"].cast(FloatType()))\n",
    "\n",
    "df_ratings1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Création des jeux d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training,test) = df_ratings1.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Création du modèle ALS et entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(maxIter=5, regParam=0.15, rank=25, userCol = \"userId\", itemCol = \"movieId\", ratingCol = \"rating\", coldStartStrategy = \"drop\", nonnegative=True)\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName = \"rmse\", labelCol = \"rating\", predictionCol = \"prediction\")\n",
    "predictions = model.transform(test)\n",
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.88\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|   385|    471|   4.0| 3.0520854|\n",
      "|   176|    471|   5.0|  3.415569|\n",
      "|   608|    471|   1.5| 3.0144289|\n",
      "|   426|    471|   5.0| 2.8086097|\n",
      "|   260|    471|   4.5| 3.0675466|\n",
      "|   104|    471|   4.5| 3.0483193|\n",
      "|    44|    833|   2.0| 1.6910638|\n",
      "|   492|    833|   4.0|  2.280677|\n",
      "|   599|   1088|   2.5| 2.4249523|\n",
      "|   169|   1088|   4.5| 4.1103616|\n",
      "+------+-------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSE = {round(rmse,3)}\")\n",
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+\n",
      "|summary|            userId|           movieId|            rating|        prediction|\n",
      "+-------+------------------+------------------+------------------+------------------+\n",
      "|  count|             19287|             19287|             19287|             19287|\n",
      "|   mean| 324.5970342717893|17643.650489967335|3.5159693057499872| 3.306959727854456|\n",
      "| stddev|181.07904248765624|33098.318950057925| 1.044572880679155|0.6646586576818803|\n",
      "|    min|                 1|                 1|               0.5|        0.14063323|\n",
      "|    max|               610|            188301|               5.0|          5.376093|\n",
      "+-------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|     1|   3527|   4.0| 4.1148076|\n",
      "|     1|   1220|   5.0|  4.333788|\n",
      "|     1|   4006|   4.0| 3.8586867|\n",
      "|     1|   3243|   3.0|  2.811433|\n",
      "|     1|   2105|   4.0| 3.6724505|\n",
      "|     1|   3793|   5.0|  4.114033|\n",
      "|     1|   3439|   4.0| 3.1371949|\n",
      "|     1|   1206|   5.0| 4.3812394|\n",
      "|     1|    919|   5.0|  4.474517|\n",
      "|     1|    163|   5.0| 3.8790586|\n",
      "|     1|   1927|   5.0|  4.417093|\n",
      "|     1|   1198|   5.0| 4.8583612|\n",
      "|     1|    157|   5.0| 3.0494716|\n",
      "|     1|   2094|   5.0| 3.8036983|\n",
      "|     1|   1127|   4.0| 4.1047835|\n",
      "|     1|   2542|   5.0|  4.624957|\n",
      "|     1|     47|   5.0|   4.46125|\n",
      "|     1|      1|   4.0|  4.445528|\n",
      "|     1|    673|   3.0| 2.8302224|\n",
      "|     1|   1291|   5.0|   4.67087|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.orderBy(predictions.userId.asc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(spark)\n",
    "predictions.registerTempTable(\"predictions_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|     1|      1|   4.0|  4.445528|\n",
      "|     1|     47|   5.0|   4.46125|\n",
      "|     1|    157|   5.0| 3.0494716|\n",
      "|     1|    163|   5.0| 3.8790586|\n",
      "|     1|    216|   5.0| 3.7912571|\n",
      "|     1|    231|   5.0| 3.2257411|\n",
      "|     1|    349|   4.0|  4.043511|\n",
      "|     1|    457|   5.0| 4.6259546|\n",
      "|     1|    527|   5.0| 4.6705804|\n",
      "|     1|    552|   4.0| 3.6677642|\n",
      "|     1|    608|   5.0| 4.5700874|\n",
      "|     1|    673|   3.0| 2.8302224|\n",
      "|     1|    919|   5.0|  4.474517|\n",
      "|     1|    940|   5.0|  4.874849|\n",
      "|     1|   1092|   5.0| 3.6729481|\n",
      "|     1|   1097|   5.0|   4.58688|\n",
      "|     1|   1127|   4.0| 4.1047835|\n",
      "|     1|   1198|   5.0| 4.8583612|\n",
      "|     1|   1206|   5.0| 4.3812394|\n",
      "|     1|   1220|   5.0|  4.333788|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('SELECT * FROM predictions_table WHERE userId = 1 ORDER BY movieId ASC').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Amélioration du modèle\n",
    "\n",
    "Pouvons-nous améliorer notre modèle avec de meilleurs hyperparamètres ? Nous allons regarder ici l'influence des paramètres de régularisations (`regParams`) et le nombre de features (`ranks`) à utiliser pour notre modèle. Nous chercherons ici à minimiser le risque moyen quadratique (***RMSE***)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_ALS(train_data, validation_data, maxIter, regParams, ranks):\n",
    "    \"\"\"\n",
    "    grid search function to select the best model based on RMSE of\n",
    "    validation data\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data: spark DF with columns ['userId', 'movieId', 'rating']\n",
    "    \n",
    "    validation_data: spark DF with columns ['userId', 'movieId', 'rating']\n",
    "    \n",
    "    maxIter: int, max number of learning iterations\n",
    "    \n",
    "    regParams: list of float, one dimension of hyper-param tuning grid\n",
    "    \n",
    "    ranks: list of float, one dimension of hyper-param tuning grid\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    The best fitted ALS model with lowest RMSE score on validation data\n",
    "    \"\"\"\n",
    "    # initial\n",
    "    min_error = float('inf')\n",
    "    best_rank = -1\n",
    "    best_regularization = 0\n",
    "    best_model = None\n",
    "    for rank in ranks:\n",
    "        print(\"\\n\")\n",
    "        for reg in regParams:\n",
    "            # get ALS model\n",
    "            als = ALS(userCol = \"userId\", itemCol = \"movieId\", ratingCol = \"rating\", coldStartStrategy = \"drop\", nonnegative=True).setMaxIter(maxIter).setRank(rank).setRegParam(reg)\n",
    "            # train ALS model\n",
    "            model = als.fit(train_data)\n",
    "            # evaluate the model by computing the RMSE on the validation data\n",
    "            predictions = model.transform(validation_data)\n",
    "            evaluator = RegressionEvaluator(metricName=\"rmse\",\n",
    "                                            labelCol=\"rating\",\n",
    "                                            predictionCol=\"prediction\")\n",
    "            rmse = evaluator.evaluate(predictions)\n",
    "            print('{} latent factors and regularization = {}: '\n",
    "                  'validation RMSE is {}'.format(rank, reg, rmse))\n",
    "            if rmse < min_error:\n",
    "                min_error = rmse\n",
    "                best_rank = rank\n",
    "                best_regularization = reg\n",
    "                best_model = model\n",
    "    print('\\nThe best model has {} latent factors and '\n",
    "          'regularization = {}'.format(best_rank, best_regularization))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "15 latent factors and regularization = 0.1: validation RMSE is 0.8865500927388011\n",
      "15 latent factors and regularization = 0.11: validation RMSE is 0.8834463507949386\n",
      "15 latent factors and regularization = 0.12: validation RMSE is 0.881677029646818\n",
      "15 latent factors and regularization = 0.13: validation RMSE is 0.8810576468880305\n",
      "15 latent factors and regularization = 0.14: validation RMSE is 0.8815189804640466\n",
      "15 latent factors and regularization = 0.15: validation RMSE is 0.8828434795303572\n",
      "15 latent factors and regularization = 0.16: validation RMSE is 0.8849297777626169\n",
      "15 latent factors and regularization = 0.17: validation RMSE is 0.8876244772649461\n",
      "15 latent factors and regularization = 0.18: validation RMSE is 0.8908040463354645\n",
      "15 latent factors and regularization = 0.19: validation RMSE is 0.8943659737958967\n",
      "15 latent factors and regularization = 0.2: validation RMSE is 0.8982350124138224\n",
      "\n",
      "\n",
      "20 latent factors and regularization = 0.1: validation RMSE is 0.8806326858710526\n",
      "20 latent factors and regularization = 0.11: validation RMSE is 0.878253648359414\n",
      "20 latent factors and regularization = 0.12: validation RMSE is 0.8773970103637836\n",
      "20 latent factors and regularization = 0.13: validation RMSE is 0.8777359599727811\n",
      "20 latent factors and regularization = 0.14: validation RMSE is 0.8790627848051065\n",
      "20 latent factors and regularization = 0.15: validation RMSE is 0.8812612683099047\n",
      "20 latent factors and regularization = 0.16: validation RMSE is 0.8841147304456737\n",
      "20 latent factors and regularization = 0.17: validation RMSE is 0.8874060048440428\n",
      "20 latent factors and regularization = 0.18: validation RMSE is 0.891054346372556\n",
      "20 latent factors and regularization = 0.19: validation RMSE is 0.8949769290727964\n",
      "20 latent factors and regularization = 0.2: validation RMSE is 0.8990883515728512\n",
      "\n",
      "\n",
      "25 latent factors and regularization = 0.1: validation RMSE is 0.8816845633376023\n",
      "25 latent factors and regularization = 0.11: validation RMSE is 0.8785689206052902\n",
      "25 latent factors and regularization = 0.12: validation RMSE is 0.877068458275183\n",
      "25 latent factors and regularization = 0.13: validation RMSE is 0.8768744635882694\n",
      "25 latent factors and regularization = 0.14: validation RMSE is 0.877805123284156\n",
      "25 latent factors and regularization = 0.15: validation RMSE is 0.879641108777148\n",
      "25 latent factors and regularization = 0.16: validation RMSE is 0.8822890619697299\n",
      "25 latent factors and regularization = 0.17: validation RMSE is 0.8855380053252951\n",
      "25 latent factors and regularization = 0.18: validation RMSE is 0.8892406717508311\n",
      "25 latent factors and regularization = 0.19: validation RMSE is 0.8932815001376776\n",
      "25 latent factors and regularization = 0.2: validation RMSE is 0.8975707100330985\n",
      "\n",
      "\n",
      "30 latent factors and regularization = 0.1: validation RMSE is 0.8804266953859091\n",
      "30 latent factors and regularization = 0.11: validation RMSE is 0.8778813458453801\n",
      "30 latent factors and regularization = 0.12: validation RMSE is 0.8766912178739432\n",
      "30 latent factors and regularization = 0.13: validation RMSE is 0.8767157457698662\n",
      "30 latent factors and regularization = 0.14: validation RMSE is 0.8777265115082332\n",
      "30 latent factors and regularization = 0.15: validation RMSE is 0.8795484585891223\n",
      "30 latent factors and regularization = 0.16: validation RMSE is 0.8820934770291868\n",
      "30 latent factors and regularization = 0.17: validation RMSE is 0.8851609572162793\n",
      "30 latent factors and regularization = 0.18: validation RMSE is 0.8886647410792076\n",
      "30 latent factors and regularization = 0.19: validation RMSE is 0.8925138700124974\n",
      "30 latent factors and regularization = 0.2: validation RMSE is 0.8966357595233937\n",
      "\n",
      "The best model has 30 latent factors and regularization = 0.12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ALS_9ed8adb55e94"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regParams = [0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17]\n",
    "ranks = [15, 20, 25, 30]\n",
    "\n",
    "tune_ALS(training, test, 5, regParams, ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons d'aller plus loin pour voir s'il est possible de faire mieux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "35 latent factors and regularization = 0.09: validation RMSE is 0.8849047802900074\n",
      "35 latent factors and regularization = 0.1: validation RMSE is 0.8794574303735211\n",
      "35 latent factors and regularization = 0.11: validation RMSE is 0.8760990976430557\n",
      "35 latent factors and regularization = 0.12: validation RMSE is 0.8745186834609052\n",
      "35 latent factors and regularization = 0.13: validation RMSE is 0.8743248082212346\n",
      "35 latent factors and regularization = 0.14: validation RMSE is 0.8752999003755378\n",
      "35 latent factors and regularization = 0.15: validation RMSE is 0.8771750481574169\n",
      "35 latent factors and regularization = 0.16: validation RMSE is 0.8798217273400061\n",
      "\n",
      "\n",
      "40 latent factors and regularization = 0.09: validation RMSE is 0.8848668695349206\n",
      "40 latent factors and regularization = 0.1: validation RMSE is 0.8801980314125837\n",
      "40 latent factors and regularization = 0.11: validation RMSE is 0.8772271384977226\n",
      "40 latent factors and regularization = 0.12: validation RMSE is 0.8757884261793065\n",
      "40 latent factors and regularization = 0.13: validation RMSE is 0.8755711550936685\n",
      "40 latent factors and regularization = 0.14: validation RMSE is 0.8764193154221915\n",
      "40 latent factors and regularization = 0.15: validation RMSE is 0.8781522029697462\n",
      "40 latent factors and regularization = 0.16: validation RMSE is 0.8806446538391032\n",
      "\n",
      "The best model has 35 latent factors and regularization = 0.13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ALS_d344abe761b1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regParams = [0.09, 0.10, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16]\n",
    "ranks = [35, 40]\n",
    "\n",
    "tune_ALS(training, test, 5, regParams, ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a donc effectivement réussi à faire un peu mieux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Création du modèle avec les meilleurs hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_als = ALS(maxIter=5, regParam=0.13, rank=35, userCol = \"userId\", itemCol = \"movieId\", ratingCol = \"rating\", coldStartStrategy = \"drop\", nonnegative=True)\n",
    "best_model = best_als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName = \"rmse\", labelCol = \"rating\", predictionCol = \"prediction\")\n",
    "predictions = best_model.transform(test)\n",
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Evaluation du nouveau modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.874\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSE = {round(rmse,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+-----------------+\n",
      "|userId|movieId|rating|prediction|rating-prediction|\n",
      "+------+-------+------+----------+-----------------+\n",
      "|   385|    471|   4.0| 3.0621886|        0.9378114|\n",
      "|   176|    471|   5.0| 3.5212595|        1.4787405|\n",
      "|   608|    471|   1.5| 3.1267812|       -1.6267812|\n",
      "|   426|    471|   5.0| 2.8944874|        2.1055126|\n",
      "|   260|    471|   4.5| 3.6802127|       0.81978726|\n",
      "+------+-------+------+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "def transform_df(df):\n",
    "    df = df.withColumn(\"prediction2\", F.round(df['prediction']*2)/2)\n",
    "    df = df.withColumn('rating-prediction2', df.rating - df.prediction2)\n",
    "    df = df.withColumn(\"rating-prediction2\", when(df['rating-prediction2'] >= 0, df['rating-prediction2']).otherwise(df['rating-prediction2']*(-1)))\n",
    "    df = df.withColumn(\"good_pred\", when(df['rating-prediction2'] <= 0.5, 1).otherwise(0)) \n",
    "    \n",
    "    return df\n",
    "\n",
    "# on arrondi la prédiction à 0.5 point près\n",
    "# on calcule la différence entre le vote de l'utilisateur et la prédiction\n",
    "# on fait en sorte d'avoir des valeurs positives\n",
    "# on calcule si notre prédiction est bonne ou non dans une tranche de 0.5 point près"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+-----------+------------------+---------+\n",
      "|userId|movieId|rating|prediction|prediction2|rating-prediction2|good_pred|\n",
      "+------+-------+------+----------+-----------+------------------+---------+\n",
      "|   385|    471|   4.0| 3.0621886|        3.0|               1.0|        0|\n",
      "|   176|    471|   5.0| 3.5212595|        3.5|               1.5|        0|\n",
      "|   608|    471|   1.5| 3.1267812|        3.0|               1.5|        0|\n",
      "|   426|    471|   5.0| 2.8944874|        3.0|               2.0|        0|\n",
      "|   260|    471|   4.5| 3.6802127|        3.5|               1.0|        0|\n",
      "+------+-------+------+----------+-----------+------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = transform_df(predictions)\n",
    "\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|summary|            userId|           movieId|            rating|        prediction|       prediction2|rating-prediction2|          good_pred|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "|  count|             19287|             19287|             19287|             19287|             19287|             19287|              19287|\n",
      "|   mean| 324.5970342717893|17643.650489967335|3.5159693057499872| 3.324669946632712|3.3243894851454345|0.6668740602478354| 0.6394462591382797|\n",
      "| stddev|181.07904248765624|33098.318950057925| 1.044572880679155|0.6805324376949697|0.6962703855299508|0.5823800625312185|0.48017360956793553|\n",
      "|    min|                 1|                 1|               0.5|        0.15309522|               0.0|               0.0|                  0|\n",
      "|    max|               610|            188301|               5.0|          5.464676|               5.5|               5.0|                  1|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|    avg(good_pred)|\n",
      "+------------------+\n",
      "|0.6394462591382797|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.groupBy().avg('good_pred').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela signifie que nous notre modèle nous permet de réaliser environ **63.9 %** de prédictions correctes, *i.e.* à plus ou moins 0.5 étoile près, sur le dataset d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Redéfinition du modèle avec un jeu de test similaire au modèle KNN afin de comparer les résultats\n",
    "\n",
    "Commençons par calculer la liste des films vus par plus de 50 utilisateurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+\n",
      "|summary|           movieId|            count|\n",
      "+-------+------------------+-----------------+\n",
      "|  count|               450|              450|\n",
      "|   mean|11245.017777777777|91.91111111111111|\n",
      "| stddev| 23457.08417001459|46.09838525896851|\n",
      "|    min|                 1|               50|\n",
      "|    max|            122904|              329|\n",
      "+-------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# liste des films vu par plus de 50 users\n",
    "list_film_test = df_ratings1.groupBy('movieId').count()\n",
    "list_film_test = list_film_test.withColumn(\"count\", list_film_test[\"count\"].cast(IntegerType())).filter(list_film_test['count'] >= 50)\n",
    "\n",
    "list_film_test.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a donc **450 films** vus par plus de 50 utilisateurs.\n",
    "\n",
    "Calculons maintenant la liste des utilisateurs ayant vus plus de 250 films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+\n",
      "|summary|           userId|            count|\n",
      "+-------+-----------------+-----------------+\n",
      "|  count|              105|              105|\n",
      "|   mean|309.6190476190476|591.1619047619048|\n",
      "| stddev|184.4623883360039|433.8280659921517|\n",
      "|    min|                6|              250|\n",
      "|    max|              610|             2698|\n",
      "+-------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# users qui ont vu plus de 250 films vus par plus de 50 users\n",
    "list_user_test = df_ratings1.groupBy('userId').count()\n",
    "list_user_test = list_user_test.withColumn(\"count\", list_user_test[\"count\"].cast(IntegerType())).filter(list_user_test['count'] >= 250)\n",
    "\n",
    "list_user_test.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et on a **105 utilisateurs** ayant vus plus de 250 films.\n",
    "\n",
    "Pour comparer avec le modèle précédent, créons un échantillon de test avec les utilisateurs qui ont vu plus de 250 films parmi ceux vus par plus de 50 users. On commence par renommer les colonnes qui nous intéressent pour plus de clarté dans la jointure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| us|\n",
      "+---+\n",
      "|580|\n",
      "|597|\n",
      "|368|\n",
      "| 28|\n",
      "|596|\n",
      "+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "list_film_test = list_film_test.select(col(\"movieId\").alias(\"mov\"))\n",
    "list_user_test = list_user_test.select(col(\"userId\").alias(\"us\"))\n",
    "\n",
    "list_user_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_ratings1.join(list_user_test, df_ratings1.userId == list_user_test.us)\n",
    "df_test = df_test.join(list_film_test, df_test.movieId == list_film_test.mov)\n",
    "df_test = df_test.drop('mov', 'us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+-----------------+\n",
      "|summary|           userId|          movieId|           rating|\n",
      "+-------+-----------------+-----------------+-----------------+\n",
      "|  count|            20041|            20041|            20041|\n",
      "|   mean|326.3430966518637|9365.241804301182|3.650541390150192|\n",
      "| stddev|184.1573170106317|  20340.317624469|0.954459974859408|\n",
      "|    min|                6|                1|              0.5|\n",
      "|    max|              610|           122904|              5.0|\n",
      "+-------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|           movieId|             count|\n",
      "+-------+------------------+------------------+\n",
      "|  count|               450|               450|\n",
      "|   mean|11245.017777777777|44.535555555555554|\n",
      "| stddev| 23457.08417001459|15.062596273004987|\n",
      "|    min|                 1|                 9|\n",
      "|    max|            122904|                98|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "essai1 = df_test.groupBy('movieId').count()\n",
    "essai1.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+\n",
      "|summary|           userId|             count|\n",
      "+-------+-----------------+------------------+\n",
      "|  count|              105|               105|\n",
      "|   mean|309.6190476190476|190.86666666666667|\n",
      "| stddev|184.4623883360039| 75.28549082130716|\n",
      "|    min|                6|                71|\n",
      "|    max|              610|               429|\n",
      "+-------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "essai2 = df_test.groupBy('userId').count()\n",
    "essai2.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a maintenant notre échantillon de test `list_test`, créons notre échantillon d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|summary|            userId|           movieId|            rating|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|  count|             80795|             80795|             80795|\n",
      "|   mean| 326.0741011201188|21933.147694783092|3.4646017699115044|\n",
      "| stddev|182.23588575047182| 37968.26498508466| 1.060015311728062|\n",
      "|    min|                 1|                 1|               0.5|\n",
      "|    max|               610|            193609|               5.0|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_training = df_ratings1.subtract(list_test)\n",
    "\n",
    "df_training.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_training.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----------------+------------------+\n",
      "|summary|            userId|         movieId|            rating|\n",
      "+-------+------------------+----------------+------------------+\n",
      "|  count|            100836|          100836|            100836|\n",
      "|   mean|326.12756356856676|19435.2957177992| 3.501556983616962|\n",
      "| stddev| 182.6184914635004|35530.9871987003|1.0425292390606342|\n",
      "|    min|                 1|               1|               0.5|\n",
      "|    max|               610|          193609|               5.0|\n",
      "+-------+------------------+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings1.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a donc bien notre échantillon d'entraînement `df_training`, préparons donc notre modèle en recherchant les meilleurs hyper-paramètres par rapport à nos nouvelles données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "20 latent factors and regularization = 0.28: validation RMSE is 1.0060292388857517\n",
      "20 latent factors and regularization = 0.3: validation RMSE is 1.0034668392364237\n",
      "20 latent factors and regularization = 0.31: validation RMSE is 1.0028625201145691\n",
      "20 latent factors and regularization = 0.32: validation RMSE is 1.002663154061755\n",
      "20 latent factors and regularization = 0.33: validation RMSE is 1.0028353922945956\n",
      "20 latent factors and regularization = 0.34: validation RMSE is 1.0033547120230608\n",
      "20 latent factors and regularization = 0.35: validation RMSE is 1.0041890187441462\n",
      "\n",
      "\n",
      "25 latent factors and regularization = 0.28: validation RMSE is 1.0022107874840231\n",
      "25 latent factors and regularization = 0.3: validation RMSE is 0.9995251202677113\n",
      "25 latent factors and regularization = 0.31: validation RMSE is 0.9989480600730523\n",
      "25 latent factors and regularization = 0.32: validation RMSE is 0.9988026436401769\n",
      "25 latent factors and regularization = 0.33: validation RMSE is 0.999050609777553\n",
      "25 latent factors and regularization = 0.34: validation RMSE is 0.9996713311828814\n",
      "25 latent factors and regularization = 0.35: validation RMSE is 1.0006198898038237\n",
      "\n",
      "\n",
      "30 latent factors and regularization = 0.28: validation RMSE is 1.0059569793587082\n",
      "30 latent factors and regularization = 0.3: validation RMSE is 1.0024097305788024\n",
      "30 latent factors and regularization = 0.31: validation RMSE is 1.0014693388176683\n",
      "30 latent factors and regularization = 0.32: validation RMSE is 1.0010023759157085\n",
      "30 latent factors and regularization = 0.33: validation RMSE is 1.000967588487172\n",
      "30 latent factors and regularization = 0.34: validation RMSE is 1.0013284225191077\n",
      "30 latent factors and regularization = 0.35: validation RMSE is 1.0020397694118934\n",
      "\n",
      "The best model has 25 latent factors and regularization = 0.32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ALS_8627431fe1bd"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regParams = [0.28, 0.30, 0.31, 0.32, 0.33, 0.34, 0.35]\n",
    "ranks = [20, 25, 30]\n",
    "\n",
    "tune_ALS(df_training, df_test, 5, regParams, ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre meilleur modèle est ici obtenu avec les hyper-paramètres explicités ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "als2 = ALS(maxIter=5, regParam=0.32, rank=25, userCol = \"userId\", itemCol = \"movieId\", ratingCol = \"rating\", coldStartStrategy = \"drop\", nonnegative=True)\n",
    "model2 = als2.fit(df_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator2 = RegressionEvaluator(metricName = \"rmse\", labelCol = \"rating\", predictionCol = \"prediction\")\n",
    "predictions2 = model2.transform(df_test)\n",
    "rmse2 = evaluator2.evaluate(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.999\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|   580|   1580|   4.0| 2.8656528|\n",
      "|   597|   1580|   3.0|  3.291853|\n",
      "|   368|   1580|   3.0| 2.4771736|\n",
      "|    28|   1580|   3.0| 2.4780116|\n",
      "|   606|   1580|   2.5| 3.0528028|\n",
      "|    91|   1580|   3.5| 2.9021473|\n",
      "|   232|   1580|   3.5| 2.8981044|\n",
      "|   599|   1580|   3.0| 2.3114977|\n",
      "|   111|   1580|   3.0| 2.9209921|\n",
      "|   140|   1580|   3.0| 3.0011435|\n",
      "+------+-------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSE = {round(rmse2,3)}\")\n",
    "predictions2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+-----------+------------------+---------+\n",
      "|userId|movieId|rating|prediction|prediction2|rating-prediction2|good_pred|\n",
      "+------+-------+------+----------+-----------+------------------+---------+\n",
      "|   580|   1580|   4.0| 2.8656528|        3.0|               1.0|        0|\n",
      "|   597|   1580|   3.0|  3.291853|        3.5|               0.5|        1|\n",
      "|   368|   1580|   3.0| 2.4771736|        2.5|               0.5|        1|\n",
      "|    28|   1580|   3.0| 2.4780116|        2.5|               0.5|        1|\n",
      "|   606|   1580|   2.5| 3.0528028|        3.0|               0.5|        1|\n",
      "+------+-------+------+----------+-----------+------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions2 = transform_df(predictions2)\n",
    "\n",
    "predictions2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+-------------------+------------------+------------------+------------------+\n",
      "|summary|            userId|          movieId|            rating|         prediction|       prediction2|rating-prediction2|         good_pred|\n",
      "+-------+------------------+-----------------+------------------+-------------------+------------------+------------------+------------------+\n",
      "|  count|             20041|            20041|             20041|              20041|             20041|             20041|             20041|\n",
      "|   mean| 326.3430966518637|9365.241804301182| 3.650541390150192|  3.087565660833581| 3.087869866773115|0.8208422733396538|0.5027693228880794|\n",
      "| stddev|184.15731701063086|20340.31762446896|0.9544599748594105|0.47425025987645064|0.4979379217160119| 0.586056554056174|0.5000048054948569|\n",
      "|    min|                 6|                1|               0.5|          1.3049136|               1.5|               0.0|                 0|\n",
      "|    max|               610|           122904|               5.0|          4.6027217|               4.5|               3.5|                 1|\n",
      "+-------+------------------+-----------------+------------------+-------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions2.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|    avg(good_pred)|\n",
      "+------------------+\n",
      "|0.5027693228880794|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions2.groupBy().avg('good_pred').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous réalisons donc environ **50.3 %** de prédictions correctes, *i.e.* à plus ou moins 0.5 étoile près, sur le dataset d'entraînement. Les résultats plus faibles que ceux obeservés précedemment, s'expliquent par le fait que nous nous sommes privés dans l'entraînement de notre modèle, des utilisateurs les plus importants en terme de volumétrie de films vus et des films les plus notés. Dans cette perspective donc, notre résultat est très satisfaisant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Amélioration de notre modèle en centrant nos données initiales\n",
    "\n",
    "Tontons maintenant une nouvelle voie d'amélioration en repartant de nos données initiales mais en les centrant avant de les injecter dans notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|      avg(rating)|\n",
      "+-----------------+\n",
      "|3.501556983616962|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rating_mean = df_ratings1.groupBy().mean('rating')\n",
    "df_rating_mean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- avg(rating): double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rating_mean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.501556983616962"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On récupère la valeur des notes moyennes\n",
    "rating_mean = df_rating_mean.collect()[0][0]\n",
    "rating_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-----------------+\n",
      "|userId|movieId|           rating|\n",
      "+------+-------+-----------------+\n",
      "|     1|      1|0.498443016383038|\n",
      "|     1|      3|0.498443016383038|\n",
      "|     1|      6|0.498443016383038|\n",
      "|     1|     47|1.498443016383038|\n",
      "|     1|     50|1.498443016383038|\n",
      "+------+-------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings2 = df_ratings1.withColumn('rating', df_ratings1['rating'] - rating_mean)\n",
    "df_ratings2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training3,test3) = df_ratings2.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "20 latent factors and regularization = 0.07: validation RMSE is 0.9690075709861126\n",
      "20 latent factors and regularization = 0.08: validation RMSE is 0.9677804506553153\n",
      "20 latent factors and regularization = 0.09: validation RMSE is 0.9671321155148779\n",
      "20 latent factors and regularization = 0.1: validation RMSE is 0.9670064219586998\n",
      "20 latent factors and regularization = 0.11: validation RMSE is 0.9674524463800205\n",
      "20 latent factors and regularization = 0.12: validation RMSE is 0.9682254307096025\n",
      "20 latent factors and regularization = 0.13: validation RMSE is 0.969177054410368\n",
      "20 latent factors and regularization = 0.14: validation RMSE is 0.9702810319701718\n",
      "\n",
      "\n",
      "25 latent factors and regularization = 0.07: validation RMSE is 0.9670064116156765\n",
      "25 latent factors and regularization = 0.08: validation RMSE is 0.9658297778804819\n",
      "25 latent factors and regularization = 0.09: validation RMSE is 0.9654430566045946\n",
      "25 latent factors and regularization = 0.1: validation RMSE is 0.9656224562128436\n",
      "25 latent factors and regularization = 0.11: validation RMSE is 0.9662691782731786\n",
      "25 latent factors and regularization = 0.12: validation RMSE is 0.9671765208876718\n",
      "25 latent factors and regularization = 0.13: validation RMSE is 0.968298363873223\n",
      "25 latent factors and regularization = 0.14: validation RMSE is 0.9695765592400696\n",
      "\n",
      "\n",
      "30 latent factors and regularization = 0.07: validation RMSE is 0.9665707452647883\n",
      "30 latent factors and regularization = 0.08: validation RMSE is 0.9659068798279985\n",
      "30 latent factors and regularization = 0.09: validation RMSE is 0.9658988804611026\n",
      "30 latent factors and regularization = 0.1: validation RMSE is 0.9662094886636362\n",
      "30 latent factors and regularization = 0.11: validation RMSE is 0.9667737924854581\n",
      "30 latent factors and regularization = 0.12: validation RMSE is 0.9675901136657384\n",
      "30 latent factors and regularization = 0.13: validation RMSE is 0.9686557287735275\n",
      "30 latent factors and regularization = 0.14: validation RMSE is 0.9698310926644801\n",
      "\n",
      "The best model has 25 latent factors and regularization = 0.09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ALS_12127f6089c7"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regParams = [0.07, 0.08, 0.09, 0.10, 0.11, 0.12, 0.13, 0.14]\n",
    "ranks = [20, 25, 30]\n",
    "\n",
    "tune_ALS(training3, test3, 5, regParams, ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "als3 = ALS(maxIter=5, regParam=0.09, rank=25, userCol = \"userId\", itemCol = \"movieId\", ratingCol = \"rating\", coldStartStrategy = \"drop\", nonnegative=True)\n",
    "model3 = als3.fit(training3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator3 = RegressionEvaluator(metricName = \"rmse\", labelCol = \"rating\", predictionCol = \"prediction\")\n",
    "predictions3 = model3.transform(test3)\n",
    "rmse3 = evaluator3.evaluate(predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.965\n",
      "+------+-------+--------------------+-----------+\n",
      "|userId|movieId|              rating| prediction|\n",
      "+------+-------+--------------------+-----------+\n",
      "|   372|    471|  -0.501556983616962|        0.0|\n",
      "|   182|    471|   0.998443016383038|0.104577005|\n",
      "|   462|    471|  -1.001556983616962| 0.09827592|\n",
      "|   171|    471|  -0.501556983616962| 0.59138185|\n",
      "|   541|    471|  -0.501556983616962| 0.45794845|\n",
      "|   357|    471|-0.00155698361696...| 0.29788032|\n",
      "|   104|    471|   0.998443016383038|0.073140234|\n",
      "|    44|    833|  -1.501556983616962| 0.10454204|\n",
      "|   599|   1088|  -1.001556983616962|        0.0|\n",
      "|   169|   1088|   0.998443016383038| 0.20165491|\n",
      "+------+-------+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSE = {round(rmse3,3)}\")\n",
    "predictions3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On décentre maintenant nos données et prédictions\n",
    "\n",
    "def transform_df2(df):\n",
    "    df = df.withColumn(\"rating\", df['rating'] + rating_mean).withColumn(\"prediction\", df['prediction'] + rating_mean)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+------------------+-----------+------------------+---------+\n",
      "|userId|movieId|rating|        prediction|prediction2|rating-prediction2|good_pred|\n",
      "+------+-------+------+------------------+-----------+------------------+---------+\n",
      "|   372|    471|   3.0| 3.501556983616962|        3.5|               0.5|        1|\n",
      "|   182|    471|   4.5|3.6061339885264774|        3.5|               1.0|        0|\n",
      "|   462|    471|   2.5|3.5998329058557887|        3.5|               1.0|        0|\n",
      "|   171|    471|   3.0| 4.092938831475391|        4.0|               1.0|        0|\n",
      "|   541|    471|   3.0|3.9595054298907657|        4.0|               1.0|        0|\n",
      "+------+-------+------+------------------+-----------+------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions3 = transform_df2(predictions3)\n",
    "predictions3 = transform_df(predictions3)\n",
    "\n",
    "predictions3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "|summary|            userId|          movieId|            rating|        prediction|        prediction2|rating-prediction2|         good_pred|\n",
      "+-------+------------------+-----------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "|  count|             19332|            19332|             19332|             19332|              19332|             19332|             19332|\n",
      "|   mean| 323.8162631905649|17218.57366025243|3.5148199875853505| 3.722910325494733|  3.701272501551831|0.7226619077177736|0.6422511897372233|\n",
      "| stddev|181.95828537786656|32964.03660919268|1.0364023577076933|0.2600996262186089|0.29831911429862595|0.6454659081565471|0.4793500650137123|\n",
      "|    min|                 1|                1|               0.5| 3.501556983616962|                3.5|               0.0|                 0|\n",
      "|    max|               610|           189333|               5.0| 5.200153699544086|                5.0|               4.0|                 1|\n",
      "+-------+------------------+-----------------+------------------+------------------+-------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions3.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|    avg(good_pred)|\n",
      "+------------------+\n",
      "|0.6422511897372233|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions3.groupBy().avg('good_pred').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En centrant nos données, nous obtenons donc environ **64.2 %** de prédictions justes. C'est légèrement mieux qu'avec notre premier modèle mais peut-être est-ce dû au split initial différent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Jointure avec les données des titres des films\n",
    "Pour plus d'interprétabilité de nos résultats, on peut joindre ce que nous avons obtenus avec les données de `movies.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|      8| Tom and Huck (1995)|  Adventure|Children|\n",
      "|      9| Sudden Death (1995)|              Action|\n",
      "|     10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_data = \"/home/p5hngk/Downloads/GitHub/SD_701---Data_Mining/ml-latest-small\"\n",
    "\n",
    "df_movies = spark.read.format(\"csv\").option(\"header\", \"true\").load(path_data+\"/movies.csv\")\n",
    "df_movies.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.join(df_movies, on=['movieId'], how='left_outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+-----------------+---------+----------------+--------------------+\n",
      "|movieId|userId|rating|prediction|rating-prediction|good_pred|           title|              genres|\n",
      "+-------+------+------+----------+-----------------+---------+----------------+--------------------+\n",
      "|      1|   596|     4| 3.2742593|        0.7257407|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   525|     4| 3.2849152|        0.7150848|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   332|     4| 3.4803617|        0.5196383|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   156|     4| 3.4410477|       0.55895233|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   534|     4|  3.994771|     0.0052289963|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|    71|     5| 3.7085998|        1.2914002|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   541|     3| 3.7809315|        0.7809315|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   277|     4|  4.053259|      0.053258896|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   275|     5| 3.9901175|        1.0098825|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|    21|     3| 2.9196885|       0.08031154|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   264|     4| 3.5826435|        0.4173565|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   167|     3| 3.3068426|       0.30684257|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   274|     4|  3.307249|       0.69275093|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   292|     4| 3.4046488|        0.5953512|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   469|     4|  3.622518|       0.37748194|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   254|     4| 3.6469126|       0.35308743|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   273|     5| 4.2104063|        0.7895937|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   161|     4|    4.1211|       0.12109995|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   134|     3| 3.7305348|        0.7305348|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   434|     4| 3.4223106|        0.5776894|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   529|     3| 3.5545669|       0.55456686|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   468|     4| 3.6943393|       0.30566072|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   601|     4| 3.9850492|      0.014950752|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   460|     4|    3.8303|        0.1696999|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   533|     5| 3.8139675|        1.1860325|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   239|     4| 3.7668579|       0.23314214|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|    63|     5| 3.2367496|        1.7632504|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|    50|     3|  2.588236|        0.4117639|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   206|     5|  4.092016|        0.9079838|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   451|     5|  3.968817|         1.031183|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   232|     3| 3.2039847|       0.20398474|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   140|     3| 3.5974844|       0.59748435|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|    31|     5|  4.045808|       0.95419216|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|    40|     5|  4.142633|       0.85736704|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   141|     4| 3.2569034|        0.7430966|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   280|     4| 3.7686403|       0.23135972|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   107|     4|  4.379612|       0.37961197|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|    15|     2| 3.1949582|        1.1949582|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   609|     3| 3.4471574|       0.44715738|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   610|     5| 3.6741738|        1.3258262|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   171|     5| 4.7204742|       0.27952576|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   380|     5| 3.9105825|        1.0894175|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   600|     2| 3.2123697|        1.2123697|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   422|     4| 3.5642686|        0.4357314|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   155|     3|  3.421243|       0.42124295|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   373|     3|  3.584734|       0.58473396|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   385|     4|  3.536365|       0.46363497|        1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|   605|     4| 3.3761423|       0.62385774|        0|Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|     6|     4| 3.8538592|       0.14614081|        1|  Jumanji (1995)|Adventure|Childre...|\n",
      "|      2|   436|     4| 3.3905978|        0.6094022|        0|  Jumanji (1995)|Adventure|Childre...|\n",
      "+-------+------+------+----------+-----------------+---------+----------------+--------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.orderBy(new.movieId.asc()).show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Réalisation de recommandations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recommendations(self, fav_movie, n_recommendations):\n",
    "    \"\"\"\n",
    "    make top n movie recommendations\n",
    "    Parameters\n",
    "    ----------\n",
    "    fav_movie: str, name of user input movie\n",
    "    n_recommendations: int, top n recommendations\n",
    "    \"\"\"\n",
    "    # get data\n",
    "    movie_user_mat_sparse, hashmap = self._prep_data()\n",
    "    # get recommendations\n",
    "    raw_recommends = self._inference(\n",
    "        self.model, movie_user_mat_sparse, hashmap,\n",
    "        fav_movie, n_recommendations)\n",
    "    # print results\n",
    "    reverse_hashmap = {v: k for k, v in hashmap.items()}\n",
    "    print('Recommendations for {}:'.format(fav_movie))\n",
    "    for i, (idx, dist) in enumerate(raw_recommends):\n",
    "        print('{0}: {1}, with distance '\n",
    "              'of {2}'.format(i+1, reverse_hashmap[idx], dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|   471|[[7842, 4.5132], ...|\n",
      "|   463|[[7842, 5.144905]...|\n",
      "|   496|[[7842, 4.533911]...|\n",
      "|   148|[[8477, 4.655421]...|\n",
      "|   540|[[7842, 5.5218005...|\n",
      "|   392|[[8477, 4.842426]...|\n",
      "|   243|[[67618, 5.862327...|\n",
      "|    31|[[33649, 5.740833...|\n",
      "|   516|[[4429, 4.7700167...|\n",
      "|   580|[[7842, 5.212381]...|\n",
      "+------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = best_model.recommendForAllUsers(10).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|movieId|     recommendations|\n",
      "+-------+--------------------+\n",
      "|   1580|[[53, 4.7668843],...|\n",
      "|   4900|[[53, 4.532554], ...|\n",
      "|   5300|[[53, 4.2717924],...|\n",
      "|   6620|[[191, 4.574413],...|\n",
      "|   7340|[[53, 3.979438], ...|\n",
      "|  32460|[[53, 5.301957], ...|\n",
      "|  54190|[[53, 5.637684], ...|\n",
      "|    471|[[53, 4.8591766],...|\n",
      "|   1591|[[37, 3.6290343],...|\n",
      "|   1342|[[171, 3.5377822]...|\n",
      "+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate top 10 user recommendations for each movie\n",
    "movieRecs = best_model.recommendForAllItems(10).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top 10 movie recommendations for a specified set of users\n",
    "users = ratings.select(als.getUserCol()).distinct().limit(3)\n",
    "userSubsetRecs = best_model.recommendForUserSubset(users, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top 10 user recommendations for a specified set of movies\n",
    "movies = ratings.select(als.getItemCol()).distinct().limit(3)\n",
    "movieSubSetRecs = best_model.recommendForItemSubset(movies, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
