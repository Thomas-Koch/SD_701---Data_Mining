{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------\n",
    "# <center>- Spark Project - SD 701 - Data Mining-</center>\n",
    "\n",
    "* https://spark.apache.org/docs/2.1.0/ml-classification-regression.html\n",
    "* https://spark.apache.org/docs/latest/mllib-collaborative-filtering.html\n",
    "* https://spark.apache.org/docs/2.2.0/ml-collaborative-filtering.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "* https://medium.com/@patelneha1495/recommendation-system-in-python-using-als-algorithm-and-apache-spark-27aca08eaab3\n",
    "* https://towardsdatascience.com/prototyping-a-recommender-system-step-by-step-part-2-alternating-least-square-als-matrix-4a76c58714a1\n",
    "\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "#from pyspark import SparkConf, SparkContext\n",
    "\n",
    "#from pyspark.ml.classification import LogisticRegression\n",
    "#from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "from pyspark.sql import Row, SparkSession\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialisation de la session spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "#conf = SparkConf() \\\n",
    "#    .setAppName(\"MovieLensALS\") \\\n",
    "#    .set(\"spark.executor.memory\", \"2g\")\n",
    "#sc = SparkContext(conf=conf)\n",
    "\n",
    "spark = SparkSession.builder.appName('Recommendation_system').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Chargement et préparation des données d'évaluations des films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "|     1|      6|   4.0|964982224|\n",
      "|     1|     47|   5.0|964983815|\n",
      "|     1|     50|   5.0|964982931|\n",
      "|     1|     70|   3.0|964982400|\n",
      "|     1|    101|   5.0|964980868|\n",
      "|     1|    110|   4.0|964982176|\n",
      "|     1|    151|   5.0|964984041|\n",
      "|     1|    157|   5.0|964984100|\n",
      "+------+-------+------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_data = \"/home/p5hngk/Downloads/GitHub/SD_701---Data_Mining/ml-latest-small\"\n",
    "\n",
    "df_ratings = spark.read.format(\"csv\").option(\"header\", \"true\").load(path_data+\"/ratings.csv\")\n",
    "df_ratings.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      1|   4.0|\n",
      "|     1|      3|   4.0|\n",
      "|     1|      6|   4.0|\n",
      "|     1|     47|   5.0|\n",
      "|     1|     50|   5.0|\n",
      "|     1|     70|   3.0|\n",
      "|     1|    101|   5.0|\n",
      "|     1|    110|   4.0|\n",
      "|     1|    151|   5.0|\n",
      "|     1|    157|   5.0|\n",
      "+------+-------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings1 = df_ratings.select(df_ratings['userId'], df_ratings['movieId'], df_ratings['rating'])\n",
    "df_ratings1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ratings1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de réaliser un modèle ALS, il faut que toutes nos données soient au format integer pour pouvoir réaliser les calculs, ce qui n'est pas le cas actuellement. Occupons-nous donc dans un premier temps de changer cela ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "df_ratings1 = df_ratings1.withColumn(\"userId\", df_ratings1[\"userId\"].cast(IntegerType())) \\\n",
    "                .withColumn(\"movieId\", df_ratings1[\"movieId\"].cast(IntegerType())) \\\n",
    "                .withColumn(\"rating\", df_ratings1[\"rating\"].cast(IntegerType()))\n",
    "\n",
    "df_ratings1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Création des jeux d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training,test) = df_ratings1.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Création du modèle ALS et entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(maxIter=5, regParam=0.09, rank=25, userCol = \"userId\", itemCol = \"movieId\", ratingCol = \"rating\", coldStartStrategy = \"drop\", nonnegative=True)\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.923\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|   602|    471|     4| 3.3281708|\n",
      "|   462|    471|     2|  2.720675|\n",
      "|   217|    471|     2| 2.6050868|\n",
      "|   171|    471|     3| 4.2653756|\n",
      "|   287|    471|     4|  2.048118|\n",
      "|   469|    471|     5| 3.3836212|\n",
      "|   307|    833|     1| 0.9147462|\n",
      "|   177|   1088|     3| 3.4987407|\n",
      "|   554|   1088|     5| 3.5295796|\n",
      "|   286|   1088|     3| 2.9365282|\n",
      "+------+-------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(metricName = \"rmse\", labelCol = \"rating\", predictionCol = \"prediction\")\n",
    "predictions = model.transform(test)\n",
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.923\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|   602|    471|     4| 3.3281708|\n",
      "|   462|    471|     2|  2.720675|\n",
      "|   217|    471|     2| 2.6050868|\n",
      "|   171|    471|     3| 4.2653756|\n",
      "|   287|    471|     4|  2.048118|\n",
      "|   469|    471|     5| 3.3836212|\n",
      "|   307|    833|     1| 0.9147462|\n",
      "|   177|   1088|     3| 3.4987407|\n",
      "|   554|   1088|     5| 3.5295796|\n",
      "|   286|   1088|     3| 2.9365282|\n",
      "+------+-------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSE = {round(rmse,3)}\")\n",
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------------+------------------+\n",
      "|summary|            userId|           movieId|           rating|        prediction|\n",
      "+-------+------------------+------------------+-----------------+------------------+\n",
      "|  count|             19335|             19335|            19335|             19335|\n",
      "|   mean|   324.51874838376|17180.324385828808|3.369847426945953|3.1990105139020804|\n",
      "| stddev|181.40932579600593|32340.785112503912|1.085566007162708|0.7425755555118295|\n",
      "|    min|                 1|                 1|                0|               0.0|\n",
      "|    max|               610|            187595|                5|          5.506267|\n",
      "+-------+------------------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|     1|   3273|     5| 2.7050326|\n",
      "|     1|    441|     4| 4.5551343|\n",
      "|     1|    163|     5| 4.0466523|\n",
      "|     1|    590|     4| 4.2134485|\n",
      "|     1|   3740|     4| 4.7146983|\n",
      "|     1|   3489|     4| 3.5443125|\n",
      "|     1|   2492|     4| 3.2470827|\n",
      "|     1|   1089|     5|  4.778551|\n",
      "|     1|   2193|     4| 4.6384244|\n",
      "|     1|   1240|     5| 4.3902125|\n",
      "|     1|   2985|     4| 3.9428837|\n",
      "|     1|   2414|     3| 3.9190807|\n",
      "|     1|   3439|     4| 3.1636713|\n",
      "|     1|   1500|     4| 4.3516064|\n",
      "|     1|   2640|     4|  4.639884|\n",
      "|     1|   1777|     4| 4.0192113|\n",
      "|     1|   2542|     5|  4.635328|\n",
      "|     1|   1927|     5| 4.4290094|\n",
      "|     1|    367|     4|  3.847385|\n",
      "|     1|      3|     4|  3.852513|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.orderBy(predictions.userId.asc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(spark)\n",
    "predictions.registerTempTable(\"predictions_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|     1|      3|     4|  3.852513|\n",
      "|     1|     50|     5| 4.5171766|\n",
      "|     1|    163|     5| 4.0466523|\n",
      "|     1|    367|     4|  3.847385|\n",
      "|     1|    441|     4| 4.5551343|\n",
      "|     1|    457|     5| 4.4773464|\n",
      "|     1|    480|     4|  4.376313|\n",
      "|     1|    527|     5|  4.645906|\n",
      "|     1|    590|     4| 4.2134485|\n",
      "|     1|   1042|     4| 3.8467429|\n",
      "|     1|   1080|     5|  4.726887|\n",
      "|     1|   1089|     5|  4.778551|\n",
      "|     1|   1097|     5| 4.4196105|\n",
      "|     1|   1213|     5| 4.7464733|\n",
      "|     1|   1240|     5| 4.3902125|\n",
      "|     1|   1282|     5| 4.4678564|\n",
      "|     1|   1408|     3| 4.8702917|\n",
      "|     1|   1500|     4| 4.3516064|\n",
      "|     1|   1777|     4| 4.0192113|\n",
      "|     1|   1805|     4| 3.6425023|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('SELECT * FROM predictions_table WHERE userId = 1 ORDER BY movieId ASC').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Amélioration du modèle\n",
    "\n",
    "Pouvons-nous améliorer notre modèle avec de meilleurs hyperparamètres ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_ALS(training, test, 10, regParams, ranks):\n",
    "    \"\"\"\n",
    "    grid search function to select the best model based on RMSE of\n",
    "    validation data\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data: spark DF with columns ['userId', 'movieId', 'rating']\n",
    "    \n",
    "    validation_data: spark DF with columns ['userId', 'movieId', 'rating']\n",
    "    \n",
    "    maxIter: int, max number of learning iterations\n",
    "    \n",
    "    regParams: list of float, one dimension of hyper-param tuning grid\n",
    "    \n",
    "    ranks: list of float, one dimension of hyper-param tuning grid\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    The best fitted ALS model with lowest RMSE score on validation data\n",
    "    \"\"\"\n",
    "    # initial\n",
    "    min_error = float('inf')\n",
    "    best_rank = -1\n",
    "    best_regularization = 0\n",
    "    best_model = None\n",
    "    for rank in ranks:\n",
    "        for reg in regParams:\n",
    "            # get ALS model\n",
    "            als = ALS().setMaxIter(maxIter).setRank(rank).setRegParam(reg)\n",
    "            # train ALS model\n",
    "            model = als.fit(train_data)\n",
    "            # evaluate the model by computing the RMSE on the validation data\n",
    "            predictions = model.transform(validation_data)\n",
    "            evaluator = RegressionEvaluator(metricName=\"rmse\",\n",
    "                                            labelCol=\"rating\",\n",
    "                                            predictionCol=\"prediction\")\n",
    "            rmse = evaluator.evaluate(predictions)\n",
    "            print('{} latent factors and regularization = {}: '\n",
    "                  'validation RMSE is {}'.format(rank, reg, rmse))\n",
    "            if rmse < min_error:\n",
    "                min_error = rmse\n",
    "                best_rank = rank\n",
    "                best_regularization = reg\n",
    "                best_model = model\n",
    "    print('\\nThe best model has {} latent factors and '\n",
    "          'regularization = {}'.format(best_rank, best_regularization))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_ALS(train_data, validation_data, maxIter, regParams, ranks):\n",
    "    \"\"\"\n",
    "    grid search function to select the best model based on RMSE of\n",
    "    validation data\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data: spark DF with columns ['userId', 'movieId', 'rating']\n",
    "    \n",
    "    validation_data: spark DF with columns ['userId', 'movieId', 'rating']\n",
    "    \n",
    "    maxIter: int, max number of learning iterations\n",
    "    \n",
    "    regParams: list of float, one dimension of hyper-param tuning grid\n",
    "    \n",
    "    ranks: list of float, one dimension of hyper-param tuning grid\n",
    "    \n",
    "    Return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Réalisation de recommandations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|     recommendations|\n",
      "+------+--------------------+\n",
      "|   471|[[8477, 4.6271734...|\n",
      "|   463|[[7842, 4.6472483...|\n",
      "|   496|[[4794, 4.539608]...|\n",
      "|   148|[[8477, 4.8804374...|\n",
      "|   540|[[171495, 5.48740...|\n",
      "|   392|[[8477, 5.045897]...|\n",
      "|   243|[[945, 5.8989525]...|\n",
      "|    31|[[3200, 5.7575874...|\n",
      "|   516|[[4429, 4.8906627...|\n",
      "|   580|[[6300, 4.9238358...|\n",
      "+------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = best_model.recommendForAllUsers(10).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|movieId|     recommendations|\n",
      "+-------+--------------------+\n",
      "|   1580|[[389, 4.588832],...|\n",
      "|   4900|[[441, 4.5939], [...|\n",
      "|   5300|[[74, 3.9770067],...|\n",
      "|   6620|[[191, 4.949128],...|\n",
      "|   7340|[[544, 4.2060995]...|\n",
      "|  32460|[[543, 5.238191],...|\n",
      "|  54190|[[544, 5.898651],...|\n",
      "|    471|[[53, 4.7354355],...|\n",
      "|   1591|[[37, 4.157173], ...|\n",
      "|   1342|[[258, 3.9858599]...|\n",
      "+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate top 10 user recommendations for each movie\n",
    "movieRecs = best_model.recommendForAllItems(10).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top 10 movie recommendations for a specified set of users\n",
    "users = ratings.select(als.getUserCol()).distinct().limit(3)\n",
    "userSubsetRecs = best_model.recommendForUserSubset(users, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top 10 user recommendations for a specified set of movies\n",
    "movies = ratings.select(als.getItemCol()).distinct().limit(3)\n",
    "movieSubSetRecs = best_model.recommendForItemSubset(movies, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
