{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercices with Spark ML\n",
    "\n",
    "This lab is split into two part. The first part is very guided and the goal to make you write a program capable of\n",
    "estimating whether a tumor is malign or benign according to a few features collected from a biopsy ! The second\n",
    "part is much more exploratory with several ML tasks on several datasets. One of the goal of this lab is to make\n",
    "you efficient at reading and using the documentation.\n",
    "\n",
    "The main page to look for the documentation of spark ML is https://spark.apache.org/docs/latest/ml-pipeline.html\n",
    "\n",
    "## The winconsin breast cancer dataset\n",
    "\n",
    "The Winconsin breast cancer dataset contains 699 cases of breast cancers. The dataset is presented here :\n",
    "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\n",
    "and you can directly download the dataset at the following URL : https://archive.ics.uci.edu/ml/\n",
    "machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data.\n",
    "\n",
    "\n",
    "Our goal here is to determine whether a tumor is malign or benign using the provided features. Each line of the dataset represents a case and contains 11 numerical values separated by commas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation de l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import random\n",
    "import os\n",
    "sc = pyspark.SparkContext(appName=\"SparkML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the data into Spark\n",
    "The first step for our ML application consist in setup up Spark and reading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.linalg import VectorUDT,Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toFloat(x):\n",
    "    if x == '?':\n",
    "        return 5.0\n",
    "    else:\n",
    "        return float(x)\n",
    "\n",
    "def doLine(l):\n",
    "    item=l.split(\",\")\n",
    "    label = 1\n",
    "    if item[10]=='2':\n",
    "        label=0\n",
    "    return (Vectors.dense([toFloat(e) for e in item[1:10]]),label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = sc.textFile(\"/home/p5hngk/Downloads/GitHub/SD_701---Data_Mining/breast-cancer-wisconsin.data\")\n",
    "schema = StructType([StructField(\"features\", VectorUDT(), True),\n",
    "                     StructField(\"label\",IntegerType(),True)])\n",
    "data = SQLContext(sc).createDataFrame(raw_data.map(doLine),schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[5.0,1.0,1.0,1.0,...|    0|\n",
      "|[5.0,4.0,4.0,5.0,...|    0|\n",
      "|[3.0,1.0,1.0,1.0,...|    0|\n",
      "|[6.0,8.0,8.0,1.0,...|    0|\n",
      "|[4.0,1.0,1.0,3.0,...|    0|\n",
      "|[8.0,10.0,10.0,8....|    1|\n",
      "|[1.0,1.0,1.0,1.0,...|    0|\n",
      "|[2.0,1.0,2.0,1.0,...|    0|\n",
      "|[2.0,1.0,1.0,1.0,...|    0|\n",
      "|[4.0,2.0,1.0,1.0,...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|  241|\n",
      "|    0|  458|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupby(data.label).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1** = malign tumors      \n",
    "**0** = begign tumors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Splitting into training and testing\n",
    "\n",
    "To build our model we first need to split our data into a training set and a testing set. Here we will split according\n",
    "to the usual 1-9 rule, which means that 90% of the dataset will be used for training while 10% will be used to test\n",
    "our model. For this you can use the function `randomSplit` (see documentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split = data.randomSplit([0.9 , 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = df_split[0]\n",
    "data_test = df_split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "636"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building the model\n",
    "\n",
    "Building the model is done using the object DecisionTree. `DecisionTreeClassifier` in the `from pyspark.ml.classification` package.\n",
    "\n",
    "\n",
    "https://spark.apache.org/docs/latest/ml-classification-regression.html#decision-tree-classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "bc_model = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\").fit(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing your model\n",
    "\n",
    "Computing predictions for the test data can be done by applying the model on the test data :\n",
    "```python\n",
    "predictions = bc_model.transform(test)\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\",\n",
    "metricName='areaUnderROC')\n",
    "result = evaluator.evaluate(predictions)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: int, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = bc_model.transform(data_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC of our classifier is : 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", metricName='areaUnderROC')\n",
    "result = evaluator.evaluate(predictions)\n",
    "print(\"The area under ROC of our classifier is : {}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error = 0.031746 \n",
      "The accuracy of our classifier is 96.82539682539682%.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator2 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator2.evaluate(predictions)\n",
    "print(\"Test error = %g \" % (1.0 - accuracy))\n",
    "print(\"The accuracy of our classifier is {}%.\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Improving the model\n",
    "\n",
    "The model is based on a set of parameters (number of bins, depth, etc.). Spark ML has tools to help you decide\n",
    "which parameters are well suited for your application (see https://spark.apache.org/docs/2.2.0/ml-tuning.html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
